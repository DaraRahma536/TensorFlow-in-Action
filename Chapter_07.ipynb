{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNKjdI9oDO1XAXm50e6AWI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaraRahma536/TensorFlow-in-Action/blob/main/Chapter_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 7: Teaching Machines to See Better: Improving CNNs and Making Them Confess**"
      ],
      "metadata": {
        "id": "qrUVcZVgSfUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Teknik untuk Mengurangi Overfitting**\n",
        "---\n",
        "Overfitting terjadi ketika model belajar terlalu baik dari data training hingga menangkap noise dan pola acak, sehingga performa buruk pada data baru. Teknik untuk mengatasinya:\n",
        "\n",
        "* **Data Augmentation:** Menciptakan variasi data training melalui transformasi gambar (rotasi, translasi, brightness, dll.) untuk membuat model lebih robust.\n",
        "* **Dropout:** Mematikan neuron secara acak selama training, memaksa model belajar representasi yang redundan.\n",
        "* **Early Stopping:** Menghentikan training ketika performa validation tidak membaik lagi.\n",
        "\n",
        "Implementasi Kode:"
      ],
      "metadata": {
        "id": "UnzkPxpMTFkr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuTkdWk6Sc2l"
      },
      "outputs": [],
      "source": [
        "# 7.1.1 Data Augmentation dengan ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Generator dengan augmentasi untuk training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Generator tanpa augmentasi untuk validation\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 7.1.2 Dropout Implementation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "    # ... layers sebelumnya\n",
        "    Dropout(0.5),  # Dropout 50%\n",
        "    # ... layers selanjutnya\n",
        "])\n",
        "\n",
        "# 7.1.3 Early Stopping Callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',    # Monitor validation loss\n",
        "    patience=10,           # Tunggu 10 epoch tanpa improvement\n",
        "    restore_best_weights=True  # Kembali ke weights terbaik\n",
        ")\n",
        "\n",
        "# Training dengan callback\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penjelasan Detail:**\n",
        "* **rotation_range=40:** Gambar dirotasi secara acak hingga 40 derajat\n",
        "* **width_shift_range=0.2:** Geser gambar hingga 20% lebarnya\n",
        "* **Dropout(0.5):** 50% neuron dimatikan secara acak setiap batch\n",
        "* **EarlyStopping:** Training berhenti jika val_loss tidak membaik selama 10 epoch"
      ],
      "metadata": {
        "id": "ua2MAELNTQ4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Menuju Minimalisme: Minception sebagai Pengganti Inception**\n",
        "---\n",
        "Minception adalah varian ringan dari Inception-ResNet-v2 dengan:\n",
        "\n",
        "* **Batch Normalization:** Normalisasi output tiap layer untuk stabilisasi training\n",
        "* **Residual Connections:** \"Shortcut\" yang menghubungkan input ke output layer\n",
        "* **Inception Blocks:** Multiple convolution paths dengan kernel size berbeda\n",
        "\n",
        "Implementasi Komponen Minception:"
      ],
      "metadata": {
        "id": "mHVQEy1gTVqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.2.1 Stem of Minception\n",
        "def stem(inp, activation='relu', bn=True):\n",
        "    conv1 = Conv2D(32, (3,3), strides=(2,2), padding='same')(inp)\n",
        "    if bn:\n",
        "        conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation(activation)(conv1)\n",
        "    # ... lebih banyak layers\n",
        "    return output\n",
        "\n",
        "# 7.2.2 Inception-ResNet Block Type A\n",
        "def inception_resnet_a(inp, n_filters, activation='relu', bn=True):\n",
        "    # Branch 1: 1x1 convolution\n",
        "    branch1 = Conv2D(n_filters[0], (1,1), padding='same')(inp)\n",
        "    if bn: branch1 = BatchNormalization()(branch1)\n",
        "\n",
        "    # Branch 2: 1x1 → 3x3 → 3x3\n",
        "    branch2 = Conv2D(n_filters[1], (1,1), padding='same')(inp)\n",
        "    branch2 = Conv2D(n_filters[2], (3,3), padding='same')(branch2)\n",
        "    branch2 = Conv2D(n_filters[3], (3,3), padding='same')(branch2)\n",
        "    if bn: branch2 = BatchNormalization()(branch2)\n",
        "\n",
        "    # Concatenate + Residual Connection\n",
        "    concat = Concatenate()([branch1, branch2])\n",
        "    output = Conv2D(n_filters[4], (1,1), padding='same')(concat)\n",
        "\n",
        "    # Residual Connection\n",
        "    if inp.shape[-1] == output.shape[-1]:\n",
        "        output = Add()([output, inp])\n",
        "\n",
        "    return Activation(activation)(output)\n",
        "\n",
        "# 7.2.5 Full Minception Model\n",
        "def build_minception(input_shape=(64,64,3), num_classes=200):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Random cropping dan contrast adjustment\n",
        "    from tensorflow.keras.layers.experimental.preprocessing import RandomCrop, RandomContrast\n",
        "    x = RandomCrop(56, 56)(inputs)\n",
        "    x = RandomContrast(0.3)(x)\n",
        "\n",
        "    # Stem\n",
        "    x = stem(x)\n",
        "\n",
        "    # Inception-ResNet Blocks\n",
        "    x = inception_resnet_a(x, [32, 32, 48, 64, 384])\n",
        "    x = reduction_block(x, [256, 256, 384, 384])\n",
        "    x = inception_resnet_b(x, [192, 128, 160, 192, 1152])\n",
        "    x = inception_resnet_b(x, [192, 128, 160, 192, 1152])\n",
        "\n",
        "    # Final Layers\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "LVqtIiCUTmED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penjelasan Komponen:**\n",
        "* **BatchNorm:** Normalisasi → Activation → Conv (urutan yang umum)\n",
        "* **Residual Connection:** output = Add()([output, input])\n",
        "* **Factorized Convolutions:** 7×7 conv dipecah menjadi 1×7 dan 7×1"
      ],
      "metadata": {
        "id": "u3Oaq4kRToOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Transfer Learning dengan Pretrained Networks**\n",
        "---\n",
        "Transfer learning menggunakan model yang sudah dilatih pada dataset besar (ImageNet) dan melakukan fine-tuning untuk task spesifik.\n",
        "\n",
        "Keuntungan:\n",
        "* Butuh data lebih sedikit\n",
        "* Training lebih cepat\n",
        "* Performa umumnya lebih baik\n",
        "\n",
        "Implementasi:"
      ],
      "metadata": {
        "id": "3raqXluHTtNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.3.1 Menggunakan Pretrained Inception-ResNet-v2\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "\n",
        "# Load pretrained model tanpa top layer\n",
        "base_model = InceptionResNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "# Freeze base model (optional)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Bangun model lengkap\n",
        "model = Sequential([\n",
        "    Input(shape=(224, 224, 3)),\n",
        "    base_model,\n",
        "    Dropout(0.4),\n",
        "    Dense(200, activation='softmax')  # 200 classes untuk tiny-ImageNet\n",
        "])\n",
        "\n",
        "# Compile dengan learning rate kecil\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 7.3.2 Fine-tuning Strategy\n",
        "def fine_tune_model(model, base_model, trainable_layers=100):\n",
        "    # Unfreeze beberapa layer terakhir\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Freeze semua layer kecuali N terakhir\n",
        "    for layer in base_model.layers[:-trainable_layers]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Recompile dengan learning rate lebih kecil\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Learning Rate Scheduling\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,      # Kurangi LR 10x\n",
        "    patience=5,      # Tunggu 5 epoch\n",
        "    min_lr=1e-7      # LR minimum\n",
        ")"
      ],
      "metadata": {
        "id": "-qA3X8Z6T1OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategi Fine-tuning:**\n",
        "* Freeze semua layer, train hanya classifier baru\n",
        "* Unfreeze beberapa layer terakhir, train bersama classifier\n",
        "* Learning rate lebih kecil untuk fine-tuning"
      ],
      "metadata": {
        "id": "4_CNXDAdT3Yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Grad-CAM: Interpretasi Model CNN**\n",
        "---\n",
        "Grad-CAM (Gradient-weighted Class Activation Mapping) memvisualisasikan area mana dalam gambar yang paling berpengaruh terhadap prediksi model.\n",
        "\n",
        "**Prinsip Kerja:**\n",
        "* Hitung gradient output class terhadap feature maps layer convolutional terakhir\n",
        "* Average pooling gradient spatial untuk mendapatkan weights tiap channel\n",
        "* Kombinasikan weighted feature maps\n",
        "* Apply ReLU untuk highlight area positif\n",
        "\n",
        "Implementasi:"
      ],
      "metadata": {
        "id": "3b2wHvSST8Do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.4.1 Implementasi Grad-CAM\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model, layer_name):\n",
        "        self.model = model\n",
        "        self.layer_name = layer_name\n",
        "        self.grad_model = tf.keras.models.Model(\n",
        "            inputs=[model.inputs],\n",
        "            outputs=[model.get_layer(layer_name).output, model.output]\n",
        "        )\n",
        "\n",
        "    def compute_heatmap(self, image, class_idx):\n",
        "        with tf.GradientTape() as tape:\n",
        "            conv_outputs, predictions = self.grad_model(image)\n",
        "            loss = predictions[:, class_idx]\n",
        "\n",
        "        # Compute gradients\n",
        "        grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "        # Pool gradients spatially\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "        # Weight feature maps by gradients\n",
        "        conv_outputs = conv_outputs[0]\n",
        "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "\n",
        "        # ReLU and normalization\n",
        "        heatmap = tf.maximum(heatmap, 0)\n",
        "        heatmap /= tf.reduce_max(heatmap)\n",
        "\n",
        "        return heatmap.numpy()\n",
        "\n",
        "    def overlay_heatmap(self, image, heatmap, alpha=0.4):\n",
        "        # Resize heatmap to match image\n",
        "        heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # Apply colormap\n",
        "        heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Superimpose\n",
        "        superimposed = cv2.addWeighted(image, 1-alpha, heatmap_colored, alpha, 0)\n",
        "\n",
        "        return superimposed\n",
        "\n",
        "# 7.4.2 Contoh Penggunaan\n",
        "def visualize_gradcam(model, image_path, layer_name='conv5_block3_out'):\n",
        "    # Load dan preprocess image\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = tf.keras.applications.inception_resnet_v2.preprocess_input(img_array)\n",
        "\n",
        "    # Predict class\n",
        "    preds = model.predict(img_array)\n",
        "    pred_class = np.argmax(preds[0])\n",
        "\n",
        "    # Compute heatmap\n",
        "    gradcam = GradCAM(model, layer_name)\n",
        "    heatmap = gradcam.compute_heatmap(img_array, pred_class)\n",
        "\n",
        "    # Visualize\n",
        "    original_img = cv2.imread(image_path)\n",
        "    original_img = cv2.resize(original_img, (224, 224))\n",
        "\n",
        "    superimposed = gradcam.overlay_heatmap(original_img, heatmap)\n",
        "\n",
        "    return original_img, superimposed, pred_class, preds[0][pred_class]"
      ],
      "metadata": {
        "id": "q4-FkB6TUONL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretasi Heatmap:**\n",
        "* Area merah: High activation, area kritis untuk prediksi\n",
        "* Area biru: Low activation, kurang relevan\n",
        "* Validasi: Cek apakah model fokus pada objek yang benar"
      ],
      "metadata": {
        "id": "ENdYeN_LUQVl"
      }
    }
  ]
}