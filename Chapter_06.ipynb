{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnTI4RHcHXj9qn86QTr09R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaraRahma536/TensorFlow-in-Action/blob/main/Chapter_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 6: Teaching Machines to See - Image Classification with CNNs**"
      ],
      "metadata": {
        "id": "GUtrr86QQlgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Exploratory Data Analysis (EDA) untuk Data Gambar**\n",
        "---\n",
        "### **A. Tujuan EDA**\n",
        "* Memahami karakteristik data\n",
        "* Mengidentifikasi masalah: class imbalance, data korup, missing values, outlier\n",
        "* Menjamin kualitas data sebelum training model\n",
        "\n",
        "### **B. Dataset: Tiny ImageNet-200**\n",
        "* Subset dari ImageNet dengan 200 kelas\n",
        "* 100,000 gambar training (500 per kelas)\n",
        "* 10,000 gambar validation\n",
        "* Format folder terstruktur:\n",
        "```\n",
        "train/\n",
        "  ├── n01443537/ (wnid)\n",
        "  │   ├── image1.JPEG\n",
        "  │   └── ...\n",
        "  └── ...\n",
        "```\n",
        "### **C. Analisis yang Dilakukan**\n",
        "* Memahami Kelas: Mapping wnid (WordNet ID) ke nama kelas melalui wnids.txt dan words.txt\n",
        "* Class Balance: Memverifikasi setiap kelas memiliki 500 gambar\n",
        "* Statistik Gambar: Ukuran gambar seragam 64x64 pixels\n",
        "* Visualisasi: Contoh gambar menunjukkan variasi konteks dan kondisi nyata\n",
        "\n",
        "**Insight Penting:** Data real-world berisik - objek tidak selalu jelas, dengan latar belakang beragam, dan terkadang terhalang."
      ],
      "metadata": {
        "id": "L45zSLMZQpri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Membuat Data Pipeline dengan Keras**\n",
        "---\n",
        "### **A. ImageDataGenerator**"
      ],
      "metadata": {
        "id": "2WAFCC5URBGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_gen = ImageDataGenerator(\n",
        "    samplewise_center=True,  # Normalisasi per gambar\n",
        "    validation_split=0.1      # Split 90% train, 10% validation\n",
        ")"
      ],
      "metadata": {
        "id": "QoxEOeAuRFCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **B. Data Generators**\n",
        "* flow_from_directory(): Untuk data terstruktur dalam folder\n",
        "* flow_from_dataframe(): Untuk data dengan label di file terpisah\n",
        "* flow(): Untuk data dalam array NumPy\n",
        "\n",
        "### **C. Implementasi Pipeline**"
      ],
      "metadata": {
        "id": "8LSFCfrcRIgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ2TEw6XQjq5"
      },
      "outputs": [],
      "source": [
        "# Training generator\n",
        "train_gen = image_gen.flow_from_directory(\n",
        "    directory='data/tiny-imagenet-200/train',\n",
        "    target_size=(56, 56),  # Resize untuk Inception Net\n",
        "    batch_size=128,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Validation generator (dari training split)\n",
        "valid_gen = image_gen.flow_from_directory(\n",
        "    ...,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Test generator (dari folder val)\n",
        "test_df = pd.read_csv('val_annotations.txt', sep='\\t')\n",
        "test_gen = image_gen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory='data/tiny-imagenet-200/val/images',\n",
        "    shuffle=False  # Penting untuk evaluasi konsisten\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **D. Modifikasi untuk Multi-Output Model**\n",
        "Inception Net memiliki 3 output layer (1 utama + 2 auxiliary), sehingga label perlu direplikasi:"
      ],
      "metadata": {
        "id": "kYkI-HTmRO61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_gen_aux(gen):\n",
        "    for x, y in gen:\n",
        "        yield x, (y, y, y)  # Satu label untuk tiga output"
      ],
      "metadata": {
        "id": "xwUOME72RRro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Inception Net: Model State-of-the-Art**\n",
        "---\n",
        "### **A. Motivasi**\n",
        "* Masalah: Model CNN dalam cenderung overfit dan membutuhkan memori besar\n",
        "* Solusi: Sparsity melalui arsitektur Inception Block\n",
        "\n",
        "### **B. Arsitektur Inception Net v1**\n",
        "**1. Stem**\n",
        "* Serangkaian layer konvolusi dan pooling awal\n",
        "* Menggunakan Local Response Normalization (LRN) (teknik normalisasi awal)\n",
        "* Output: Feature maps dengan dimensi tertentu\n",
        "\n",
        "**2. Inception Block (Konsep Inti)**\n",
        "* Paralel convolution layers dengan kernel size berbeda (1x1, 3x3, 5x5)\n",
        "* Concatenation output semua parallel streams\n",
        "* Manfaat:\n",
        "-&nbsp;Sparsity: Koneksi lebih jarang daripada convolution tunggal  \n",
        "-&nbsp;Parameter Efficiency: Lebih sedikit parameter dengan kemampuan representasi sama  \n",
        "-&nbsp;Multi-scale features: Menangkap pola pada skala berbeda  \n",
        "* Analogi: Alih-alih filter 5x5 tunggal, gunakan kombinasi 1x1, 3x3, dan 5x5 yang lebih efisien.  \n",
        "\n",
        "**3. 1×1 Convolutions sebagai Dimensionality Reduction**\n",
        "* Mengurangi channel depth sebelum convolution mahal (3x3, 5x5)\n",
        "* Contoh: Input 256 channel → 1x1 conv → 64 channel → 3x3 conv\n",
        "* Pengurangan parameter signifikan\n",
        "\n",
        "**4. Auxiliary Output Layers**\n",
        "* Dua output tambahan di tengah jaringan\n",
        "* Fungsi: Stabilisasi training deep network\n",
        "* Membantu gradient flow ke layer awal\n",
        "\n",
        "### **C. Implementasi Inception Block**"
      ],
      "metadata": {
        "id": "URikBrRPRSn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inception(inp, n_filters):\n",
        "    # Stream 1: 1x1 convolution\n",
        "    out1 = Conv2D(n_filters[0][0], (1,1), activation='relu', padding='same')(inp)\n",
        "\n",
        "    # Stream 2: 1x1 → 3x3\n",
        "    out2_1 = Conv2D(n_filters[1][0], (1,1), activation='relu', padding='same')(inp)\n",
        "    out2_2 = Conv2D(n_filters[1][1], (3,3), activation='relu', padding='same')(out2_1)\n",
        "\n",
        "    # Stream 3: 1x1 → 5x5\n",
        "    out3_1 = Conv2D(n_filters[2][0], (1,1), activation='relu', padding='same')(inp)\n",
        "    out3_2 = Conv2D(n_filters[2][1], (5,5), activation='relu', padding='same')(out3_1)\n",
        "\n",
        "    # Stream 4: 3x3 pool → 1x1\n",
        "    out4_1 = MaxPool2D((3,3), strides=(1,1), padding='same')(inp)\n",
        "    out4_2 = Conv2D(n_filters[3][0], (1,1), activation='relu', padding='same')(out4_1)\n",
        "\n",
        "    # Concatenate semua stream\n",
        "    out = Concatenate(axis=-1)([out1, out2_2, out3_2, out4_2])\n",
        "    return out"
      ],
      "metadata": {
        "id": "B45iZ3CXR2kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **D. Model Lengkap Inception v1**"
      ],
      "metadata": {
        "id": "1x_XXNESR4YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_v1():\n",
        "    inp = Input(shape=(56, 56, 3))\n",
        "\n",
        "    # Stem\n",
        "    stem_out = stem(inp)\n",
        "\n",
        "    # Inception blocks (9 blocks sesuai paper)\n",
        "    inc_3a = inception(stem_out, [(64,), (96,128), (16,32), (32,)])\n",
        "    inc_3b = inception(inc_3a, [(128,), (128,192), (32,96), (64,)])\n",
        "    # ... (7 blocks lainnya)\n",
        "\n",
        "    # Auxiliary outputs\n",
        "    aux_out1 = aux_out(inc_4a, name='aux1')\n",
        "    aux_out2 = aux_out(inc_4d, name='aux2')\n",
        "\n",
        "    # Final layers\n",
        "    avgpool = AvgPool2D((7,7), strides=(1,1), padding='valid')(inc_5b)\n",
        "    flat = Flatten()(avgpool)\n",
        "    out_main = Dense(200, activation='softmax', name='final')(flat)\n",
        "\n",
        "    # Multi-output model\n",
        "    model = Model(inputs=inp, outputs=[out_main, aux_out1, aux_out2])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    return model"
      ],
      "metadata": {
        "id": "btiTUTNqR5L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Training dan Evaluasi**\n",
        "---\n",
        "### **A. Training Process**"
      ],
      "metadata": {
        "id": "Yng2LF1DR7mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x=train_gen_aux,\n",
        "    validation_data=valid_gen_aux,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=50,\n",
        "    callbacks=[CSVLogger('training_log.csv')]\n",
        ")"
      ],
      "metadata": {
        "id": "Ek6qzP4ZR_1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **B. Hasil Training**\n",
        "* Training accuracy: ~94% (sangat tinggi)\n",
        "* Validation/Test accuracy: ~27-30% (rendah)\n",
        "* Indikasi kuat overfitting\n",
        "\n",
        "### **C. Analisis Overfitting**\n",
        "Penyebab:\n",
        "* Model terlalu kompleks untuk dataset\n",
        "* Kurang regularisasi\n",
        "* Tidak menggunakan pretrained weights\n",
        "\n",
        "Analogi: Siswa yang menghafal jawaban (overfit) vs memahami konsep (generalize)."
      ],
      "metadata": {
        "id": "z5y8b_MrSCC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Evolusi Inception Models**\n",
        "---\n",
        "### **A. Inception v2**\n",
        "* Factorization: Ganti 5x5 convolution dengan dua 3x3 convolution\n",
        "* Parameter reduction: 28% lebih sedikit parameter\n",
        "* Ganti 3x3 dengan 1x3 + 3x1 untuk efisiensi lebih\n",
        "\n",
        "### **B. Inception v3**\n",
        "* Tambah Batch Normalization\n",
        "* RMSProp optimizer dengan learning rate decay\n",
        "* Label smoothing regularization\n",
        "\n",
        "### **C. Inception v4 & Inception-ResNet**\n",
        "* Simplifikasi arsitektur\n",
        "* Residual connections (skip connections)\n",
        "* Kombinasi Inception blocks dengan ResNet"
      ],
      "metadata": {
        "id": "BYUYV3qYSMGh"
      }
    }
  ]
}